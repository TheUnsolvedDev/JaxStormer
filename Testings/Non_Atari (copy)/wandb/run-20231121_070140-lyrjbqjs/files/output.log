***********************************
[31mTraining started on ENV [34mCartPole-v1
[37m***********************************
[37m[3m                             Q_model_small Summary                              
â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m path    [22mâ”ƒ[1m module        [22mâ”ƒ[1m inputs      [22mâ”ƒ[1m outputs     [22mâ”ƒ[1m params                 [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚         â”‚ Q_model_small â”‚ float32[4]  â”‚ float32[2]  â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dense_0 â”‚ Dense         â”‚ float32[4]  â”‚ float32[16] â”‚ bias: float32[16]      â”‚
â”‚         â”‚               â”‚             â”‚             â”‚ kernel: float32[4,16]  â”‚
â”‚         â”‚               â”‚             â”‚             â”‚                        â”‚
â”‚         â”‚               â”‚             â”‚             â”‚ [1m80 (320 B)[22m             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dense_1 â”‚ Dense         â”‚ float32[16] â”‚ float32[16] â”‚ bias: float32[16]      â”‚
â”‚         â”‚               â”‚             â”‚             â”‚ kernel: float32[16,16] â”‚
â”‚         â”‚               â”‚             â”‚             â”‚                        â”‚
â”‚         â”‚               â”‚             â”‚             â”‚ [1m272 (1.1 KB)[22m           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dense_2 â”‚ Dense         â”‚ float32[16] â”‚ float32[2]  â”‚ bias: float32[2]       â”‚
â”‚         â”‚               â”‚             â”‚             â”‚ kernel: float32[16,2]  â”‚
â”‚         â”‚               â”‚             â”‚             â”‚                        â”‚
â”‚         â”‚               â”‚             â”‚             â”‚ [1m34 (136 B)[22m             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚[1m         [22mâ”‚[1m               [22mâ”‚[1m             [22mâ”‚[1m       Total [22mâ”‚[1m 386 (1.5 KB)           [22mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1m                                                                                
[1m                         Total Parameters: 386 (1.5 KB)                         







  3%|â–ˆâ–ˆâ–ˆâ–                                                                                                                    | 2901/100001 [00:20<27:47, 58.25it/s]
  3%|â–ˆâ–ˆâ–ˆâ–Œ                                                                                                                   | 3000/100001 [00:22<12:19, 131.14it/s]
Traceback (most recent call last):
  File "/home/shuvrajeet/Documents/GitHub/JaxStormer/ReinforcementLearning/Non_Atari (copy)/main.py", line 133, in <module>
    main()
  File "/home/shuvrajeet/Documents/GitHub/JaxStormer/ReinforcementLearning/Non_Atari (copy)/main.py", line 129, in main
    agent.train()
  File "/home/shuvrajeet/Documents/GitHub/JaxStormer/ReinforcementLearning/Non_Atari (copy)/dqn.py", line 169, in train
    save_data(data=[step, jax.device_get(
  File "/home/shuvrajeet/Documents/GitHub/JaxStormer/ReinforcementLearning/Non_Atari (copy)/utils.py", line 14, in save_data
    os.makedirs(file.replace('logs.txt', ''), exist_ok=True)
  File "<frozen os>", line 225, in makedirs
FileNotFoundError: [Errno 2] No such file or directory: ''