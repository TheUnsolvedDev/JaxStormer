***********************************
[31mTraining started on ENV [34mCartPole-v1
[37m***********************************
[37m[3m                             Q_model_small Summary                              
┏━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m path    [22m┃[1m module        [22m┃[1m inputs      [22m┃[1m outputs     [22m┃[1m params                 [22m┃
┡━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩
│         │ Q_model_small │ float32[4]  │ float32[2]  │                        │
├─────────┼───────────────┼─────────────┼─────────────┼────────────────────────┤
│ Dense_0 │ Dense         │ float32[4]  │ float32[16] │ bias: float32[16]      │
│         │               │             │             │ kernel: float32[4,16]  │
│         │               │             │             │                        │
│         │               │             │             │ [1m80 (320 B)[22m             │
├─────────┼───────────────┼─────────────┼─────────────┼────────────────────────┤
│ Dense_1 │ Dense         │ float32[16] │ float32[16] │ bias: float32[16]      │
│         │               │             │             │ kernel: float32[16,16] │
│         │               │             │             │                        │
│         │               │             │             │ [1m272 (1.1 KB)[22m           │
├─────────┼───────────────┼─────────────┼─────────────┼────────────────────────┤
│ Dense_2 │ Dense         │ float32[16] │ float32[2]  │ bias: float32[2]       │
│         │               │             │             │ kernel: float32[16,2]  │
│         │               │             │             │                        │
│         │               │             │             │ [1m34 (136 B)[22m             │
├─────────┼───────────────┼─────────────┼─────────────┼────────────────────────┤
│[1m         [22m│[1m               [22m│[1m             [22m│[1m       Total [22m│[1m 386 (1.5 KB)           [22m│
└─────────┴───────────────┴─────────────┴─────────────┴────────────────────────┘
[1m                                                                                
[1m                         Total Parameters: 386 (1.5 KB)                         
  2%|██▍                                                                                                                    | 2010/100001 [00:02<02:11, 744.93it/s]
Traceback (most recent call last):
  File "/home/shuvrajeet/Documents/GitHub/JaxStormer/ReinforcementLearning/Non_Atari (copy)/main.py", line 133, in <module>
    main()
  File "/home/shuvrajeet/Documents/GitHub/JaxStormer/ReinforcementLearning/Non_Atari (copy)/main.py", line 129, in main
    agent.train()
  File "/home/shuvrajeet/Documents/GitHub/JaxStormer/ReinforcementLearning/Non_Atari (copy)/dqn.py", line 141, in train
    states, actions, rewards, next_states, dones = self.replay_buffer.get_batch(
                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/shuvrajeet/Documents/GitHub/JaxStormer/ReinforcementLearning/Non_Atari (copy)/memory.py", line 23, in get_batch
    states = jnp.array(states).reshape((NUM_ENVS*len(indices), -1))
                                        ^^^^^^^^
NameError: name 'NUM_ENVS' is not defined